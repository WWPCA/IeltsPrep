#!/usr/bin/env python3
"""
Clean UI and Fix Voice Issues
1. Remove Nova Sonic Features box (users don't need to see backend details)
2. Remove Nova Sonic Status box (not relevant to IELTS test)
3. Fix Nova Sonic connection with proper fallback to working voice
"""

import boto3
import json
import zipfile
import time

def create_clean_ui_lambda():
    """Create Lambda with clean UI and working voice"""
    
    lambda_code = '''
import json
import uuid
import boto3
import os
import base64
from datetime import datetime
from typing import Dict, Any, Optional

# Complete assessment questions with "Hello" greeting
MOCK_QUESTIONS = {
    "academic_speaking": {
        "question_id": "as_001",
        "question_text": "Academic Speaking Assessment with Maya AI Examiner",
        "maya_questions": [
            {
                "part": 1,
                "question": "Hello! I am Maya, your AI examiner for this IELTS Speaking assessment. Let me start by asking you some questions about yourself. What is your name and where are you from?",
                "expected_duration": 30
            },
            {
                "part": 1,
                "question": "That is interesting. Can you tell me about your work or studies?",
                "expected_duration": 45
            },
            {
                "part": 1,
                "question": "What do you enjoy doing in your free time?",
                "expected_duration": 45
            },
            {
                "part": 2,
                "question": "Now I will give you a topic card. You have one minute to prepare and then speak for 1-2 minutes. Describe a memorable journey you have taken. You should say: where you went, who you went with, what you did there, and explain why this journey was memorable for you.",
                "expected_duration": 120,
                "prep_time": 60
            },
            {
                "part": 3,
                "question": "Let us discuss travel and journeys in general. How has travel changed in your country over the past few decades?",
                "expected_duration": 60
            },
            {
                "part": 3,
                "question": "What are the benefits of traveling to different countries?",
                "expected_duration": 60
            }
        ]
    }
}

def lambda_handler(event, context):
    """Main AWS Lambda handler"""
    try:
        path = event.get("path", "/")
        method = event.get("httpMethod", "GET")
        
        if path == "/":
            return handle_home_page()
        elif path == "/assessment/academic-speaking":
            return handle_speaking_assessment()
        elif path == "/api/nova-sonic/speak":
            return handle_voice_synthesis(event.get("body", ""))
        elif path == "/api/health":
            return handle_health_check()
        else:
            return {"statusCode": 404, "headers": {"Content-Type": "text/html"}, "body": "<h1>404 Not Found</h1>"}
    except Exception as e:
        return {"statusCode": 500, "headers": {"Content-Type": "application/json"}, "body": json.dumps({"error": str(e)})}

def handle_home_page():
    """Handle home page"""
    html = """<!DOCTYPE html>
<html>
<head>
    <title>IELTS GenAI Prep</title>
    <style>
        body { font-family: Arial, sans-serif; padding: 20px; background-color: #f5f5f5; }
        .container { max-width: 1000px; margin: 0 auto; background: white; padding: 40px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        h1 { color: #e31e24; margin-bottom: 10px; font-size: 32px; }
        .assessment-card { background: #f8f9fa; padding: 25px; border-radius: 8px; border: 1px solid #ddd; margin: 20px 0; }
        .btn { background-color: #e31e24; color: white; padding: 12px 24px; border: none; border-radius: 4px; cursor: pointer; text-decoration: none; display: inline-block; font-weight: bold; }
        .btn:hover { background-color: #c21a1f; }
    </style>
</head>
<body>
    <div class="container">
        <h1>IELTS GenAI Prep</h1>
        <p>AI-powered IELTS preparation platform with Maya AI examiner</p>
        
        <div class="assessment-card">
            <h3>Academic Speaking Assessment</h3>
            <p><strong>Maya AI Examiner:</strong> Professional British female voice<br>
               <strong>Assessment Format:</strong> Official IELTS 3-part structure<br>
               <strong>Duration:</strong> 11-14 minutes total</p>
            <a href="/assessment/academic-speaking" class="btn">Start Assessment</a>
        </div>
    </div>
</body>
</html>"""
    
    return {"statusCode": 200, "headers": {"Content-Type": "text/html"}, "body": html}

def handle_speaking_assessment():
    """Handle speaking assessment with clean UI and working voice"""
    maya_questions = MOCK_QUESTIONS["academic_speaking"]["maya_questions"]
    maya_questions_json = json.dumps(maya_questions)
    
    html = f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Academic Speaking Assessment</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{ font-family: Arial, sans-serif; background-color: #f5f5f5; }}
        .header {{ background-color: #fff; padding: 15px 20px; border-bottom: 1px solid #ddd; display: flex; justify-content: space-between; align-items: center; }}
        .logo {{ background-color: #e31e24; color: white; padding: 8px 12px; font-weight: bold; font-size: 18px; }}
        .timer {{ background-color: #333; color: white; padding: 8px 15px; border-radius: 4px; font-weight: bold; }}
        .main-content {{ display: flex; height: calc(100vh - 120px); background-color: #fff; }}
        .question-panel {{ width: 50%; padding: 20px; border-right: 1px solid #ddd; overflow-y: auto; }}
        .answer-panel {{ width: 50%; padding: 20px; display: flex; flex-direction: column; }}
        .part-header {{ background-color: #f8f8f8; padding: 10px 15px; margin-bottom: 20px; border-left: 4px solid #e31e24; }}
        .maya-chat {{ flex: 1; border: 1px solid #ddd; border-radius: 4px; padding: 15px; background-color: #f9f9f9; display: flex; flex-direction: column; }}
        .maya-messages {{ flex: 1; overflow-y: auto; margin-bottom: 15px; }}
        .maya-message {{ padding: 10px; margin-bottom: 10px; background-color: white; border-radius: 4px; }}
        .maya-message.user {{ background-color: #e3f2fd; }}
        .maya-message.maya {{ background-color: #f3e5f5; }}
        .conversation-status {{ padding: 10px; background-color: #f8f9fa; border: 1px solid #ddd; border-radius: 4px; margin-bottom: 15px; }}
        .recording-controls {{ display: flex; gap: 10px; margin-bottom: 15px; flex-wrap: wrap; }}
        .footer {{ display: flex; justify-content: space-between; padding: 15px 20px; background-color: #f8f8f8; border-top: 1px solid #ddd; }}
        .btn {{ padding: 10px 20px; border: none; border-radius: 4px; font-size: 14px; font-weight: bold; cursor: pointer; }}
        .btn-record {{ background-color: #dc3545; color: white; }}
        .btn-stop {{ background-color: #6c757d; color: white; }}
        .btn-submit {{ background-color: #28a745; color: white; }}
        .btn:disabled {{ background-color: #e9ecef; color: #6c757d; cursor: not-allowed; }}
        @media (max-width: 768px) {{
            .main-content {{ flex-direction: column; height: auto; }}
            .question-panel, .answer-panel {{ width: 100%; }}
            .question-panel {{ border-right: none; border-bottom: 1px solid #ddd; }}
        }}
    </style>
</head>
<body>
    <div class="header">
        <div>
            <div class="logo">IELTS GenAI</div>
            <div style="font-size: 14px; color: #666;">Test taker: test@example.com</div>
        </div>
        <div class="timer" id="timer">--:--</div>
    </div>
    
    <div class="main-content">
        <div class="question-panel">
            <div class="part-header">
                <div style="font-size: 16px; font-weight: bold;">IELTS Speaking Assessment</div>
                <div style="font-size: 14px; color: #666;">
                    Complete 3-part assessment with Maya AI examiner
                </div>
            </div>
            
            <div style="line-height: 1.6; margin-bottom: 20px;">
                <h4>Assessment Structure:</h4>
                <p><strong>Part 1:</strong> Interview (4-5 minutes)<br>
                   <strong>Part 2:</strong> Long Turn (3-4 minutes)<br>
                   <strong>Part 3:</strong> Discussion (4-5 minutes)</p>
            </div>
            
            <div style="padding: 15px; background-color: #e8f4fd; border: 1px solid #0066cc; border-radius: 4px;">
                <strong>Assessment Instructions:</strong><br>
                ‚Ä¢ Maya will ask you questions in each part<br>
                ‚Ä¢ Listen carefully to each question<br>
                ‚Ä¢ Record your response when prompted<br>
                ‚Ä¢ Speak clearly and naturally<br>
                ‚Ä¢ Complete all three parts of the assessment
            </div>
        </div>
        
        <div class="answer-panel">
            <div class="maya-chat">
                <div class="maya-messages" id="mayaMessages">
                    <!-- Messages will be added here -->
                </div>
                
                <div class="conversation-status" id="conversationStatus">
                    Welcome! Maya will begin the assessment automatically in 3 seconds...
                </div>
                
                <div class="recording-controls">
                    <button class="btn btn-record" id="recordBtn" disabled>Start Recording</button>
                    <button class="btn btn-stop" id="stopBtn" disabled>Stop Recording</button>
                </div>
            </div>
        </div>
    </div>
    
    <div class="footer">
        <div>Current Part: <span id="currentPart">1</span> of 3</div>
        <div>Question: <span id="currentQuestion">1</span> of <span id="totalQuestions">6</span></div>
        <div><button class="btn btn-submit" id="submitBtn" disabled>Complete Assessment</button></div>
    </div>
    
    <script>
        let timeRemaining = 0;
        let timerStarted = false;
        let currentQuestionIndex = 0;
        let isRecording = false;
        let mediaRecorder;
        let audioChunks = [];
        let speechSynthesis = window.speechSynthesis;
        let mayaVoice = null;
        
        const timer = document.getElementById('timer');
        const recordBtn = document.getElementById('recordBtn');
        const stopBtn = document.getElementById('stopBtn');
        const submitBtn = document.getElementById('submitBtn');
        const conversationStatus = document.getElementById('conversationStatus');
        const mayaMessages = document.getElementById('mayaMessages');
        const currentPart = document.getElementById('currentPart');
        const currentQuestion = document.getElementById('currentQuestion');
        
        // Maya questions data
        const mayaQuestions = {maya_questions_json};
        
        // Initialize Maya voice with fallback
        function initializeMayaVoice() {{
            const voices = speechSynthesis.getVoices();
            
            // Find best British female voice
            mayaVoice = voices.find(voice => 
                voice.lang.includes('en-GB') && voice.name.toLowerCase().includes('female')
            ) || voices.find(voice => 
                voice.lang.includes('en-GB') && voice.name.toLowerCase().includes('woman')
            ) || voices.find(voice => 
                voice.lang.includes('en-GB')
            ) || voices.find(voice => 
                voice.lang.includes('en-US') && voice.name.toLowerCase().includes('female')
            ) || voices.find(voice => 
                voice.lang.includes('en')
            ) || voices[0];
            
            console.log('Maya voice initialized:', mayaVoice?.name || 'Default voice');
        }}
        
        // Initialize voices
        if (speechSynthesis.getVoices().length > 0) {{
            initializeMayaVoice();
        }} else {{
            speechSynthesis.onvoiceschanged = initializeMayaVoice;
        }}
        
        function updateTimer() {{
            if (!timerStarted) return;
            
            const minutes = Math.floor(timeRemaining / 60);
            const seconds = timeRemaining % 60;
            timer.textContent = minutes.toString().padStart(2, '0') + ':' + seconds.toString().padStart(2, '0');
            
            if (timeRemaining <= 0) {{
                alert('Assessment time is up!');
                return;
            }}
            
            timeRemaining--;
        }}
        
        function startTimer() {{
            if (!timerStarted) {{
                timerStarted = true;
                timeRemaining = 15 * 60; // 15 minutes
                conversationStatus.textContent = 'Assessment timer started. Maya will now begin the conversation.';
                conversationStatus.style.backgroundColor = '#d4edda';
                setInterval(updateTimer, 1000);
            }}
        }}
        
        function addMayaMessage(message, isMaya = true) {{
            const messageDiv = document.createElement('div');
            messageDiv.className = 'maya-message ' + (isMaya ? 'maya' : 'user');
            messageDiv.innerHTML = isMaya ? '<strong>Maya (AI Examiner):</strong> ' + message : '<strong>You:</strong> ' + message;
            mayaMessages.appendChild(messageDiv);
            mayaMessages.scrollTop = mayaMessages.scrollHeight;
        }}
        
        function playMayaVoice(questionText) {{
            return new Promise((resolve) => {{
                // Try API first, then fallback to browser voice
                fetch('/api/nova-sonic/speak', {{
                    method: 'POST',
                    headers: {{ 'Content-Type': 'application/json' }},
                    body: JSON.stringify({{ text: questionText }})
                }})
                .then(response => response.json())
                .then(data => {{
                    if (data.success && data.audio_base64) {{
                        // Play API audio
                        const audio = new Audio('data:audio/mp3;base64,' + data.audio_base64);
                        audio.onended = resolve;
                        audio.onerror = () => useBrowserVoice();
                        audio.play();
                    }} else {{
                        useBrowserVoice();
                    }}
                }})
                .catch(error => {{
                    console.log('API unavailable, using browser voice');
                    useBrowserVoice();
                }});
                
                function useBrowserVoice() {{
                    if (!mayaVoice) {{
                        resolve();
                        return;
                    }}
                    
                    const utterance = new SpeechSynthesisUtterance(questionText);
                    utterance.voice = mayaVoice;
                    utterance.rate = 0.85;
                    utterance.pitch = 1.0;
                    utterance.volume = 1.0;
                    
                    utterance.onstart = function() {{
                        conversationStatus.textContent = 'Maya is speaking... Please listen carefully.';
                        conversationStatus.style.backgroundColor = '#fff3cd';
                    }};
                    
                    utterance.onend = function() {{
                        conversationStatus.textContent = 'Maya has finished. Please record your response.';
                        conversationStatus.style.backgroundColor = '#d1ecf1';
                        recordBtn.disabled = false;
                        
                        if (currentQuestionIndex === 0) {{
                            startTimer();
                        }}
                        
                        resolve();
                    }};
                    
                    utterance.onerror = function(error) {{
                        console.error('Speech synthesis error:', error);
                        conversationStatus.textContent = 'Maya question displayed. Please record your response.';
                        conversationStatus.style.backgroundColor = '#d1ecf1';
                        recordBtn.disabled = false;
                        
                        if (currentQuestionIndex === 0) {{
                            startTimer();
                        }}
                        
                        resolve();
                    }};
                    
                    speechSynthesis.speak(utterance);
                }}
            }});
        }}
        
        function loadNextQuestion() {{
            if (currentQuestionIndex >= mayaQuestions.length) {{
                addMayaMessage('Thank you for completing the IELTS Speaking assessment. Your responses have been recorded.');
                conversationStatus.textContent = 'Assessment complete! Click "Complete Assessment" to finish.';
                conversationStatus.style.backgroundColor = '#d4edda';
                submitBtn.disabled = false;
                recordBtn.disabled = true;
                return;
            }}
            
            const question = mayaQuestions[currentQuestionIndex];
            
            // Add Maya message
            addMayaMessage(question.question);
            currentPart.textContent = question.part;
            currentQuestion.textContent = currentQuestionIndex + 1;
            
            // Play Maya voice
            setTimeout(() => {{
                playMayaVoice(question.question);
            }}, 1000);
        }}
        
        // Initialize assessment
        setTimeout(() => {{
            conversationStatus.textContent = 'Maya will begin speaking in 1 second...';
            conversationStatus.style.backgroundColor = '#e8f4fd';
            
            setTimeout(() => {{
                loadNextQuestion();
            }}, 1000);
        }}, 3000);
        
        // Recording controls
        recordBtn.addEventListener('click', async function() {{
            try {{
                const stream = await navigator.mediaDevices.getUserMedia({{ audio: true }});
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];
                
                mediaRecorder.ondataavailable = function(event) {{
                    audioChunks.push(event.data);
                }};
                
                mediaRecorder.onstart = function() {{
                    isRecording = true;
                    recordBtn.disabled = true;
                    stopBtn.disabled = false;
                    conversationStatus.textContent = 'Recording your response... Speak clearly and naturally.';
                    conversationStatus.style.backgroundColor = '#fff3cd';
                }};
                
                mediaRecorder.onstop = function() {{
                    isRecording = false;
                    recordBtn.disabled = false;
                    stopBtn.disabled = true;
                    conversationStatus.textContent = 'Response recorded. Moving to next question...';
                    conversationStatus.style.backgroundColor = '#d4edda';
                    
                    addMayaMessage('Response recorded for Part ' + mayaQuestions[currentQuestionIndex].part, false);
                    
                    // Move to next question
                    currentQuestionIndex++;
                    setTimeout(() => {{
                        loadNextQuestion();
                    }}, 2000);
                }};
                
                mediaRecorder.start();
                
                // Auto-stop after expected duration + 30 seconds
                const maxDuration = (mayaQuestions[currentQuestionIndex].expected_duration || 60) + 30;
                setTimeout(() => {{
                    if (isRecording) {{
                        mediaRecorder.stop();
                    }}
                }}, maxDuration * 1000);
                
            }} catch (error) {{
                alert('Error accessing microphone. Please ensure microphone permissions are enabled.');
                conversationStatus.textContent = 'Error: Could not access microphone. Please check permissions.';
                conversationStatus.style.backgroundColor = '#f8d7da';
            }}
        }});
        
        stopBtn.addEventListener('click', function() {{
            if (mediaRecorder && isRecording) {{
                mediaRecorder.stop();
            }}
        }});
    </script>
</body>
</html>"""
    
    return {"statusCode": 200, "headers": {"Content-Type": "text/html"}, "body": html}

def handle_voice_synthesis(body):
    """Handle voice synthesis with proper fallback"""
    try:
        data = json.loads(body) if body else {}
        text = data.get('text', '')
        
        if not text:
            return {
                "statusCode": 400,
                "headers": {"Content-Type": "application/json"},
                "body": json.dumps({"success": False, "error": "No text provided"})
            }
        
        # Try Nova Sonic API first
        try:
            bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')
            
            # Simplified request for Nova Sonic
            request_body = {
                "inputText": text,
                "voiceId": "British-Female-Professional"
            }
            
            response = bedrock.invoke_model(
                modelId='amazon.nova-sonic-v1:0',
                body=json.dumps(request_body),
                contentType='application/json'
            )
            
            result = json.loads(response['body'].read())
            
            if 'audioStream' in result:
                return {
                    "statusCode": 200,
                    "headers": {"Content-Type": "application/json"},
                    "body": json.dumps({
                        "success": True,
                        "audio_base64": result['audioStream'],
                        "voice_type": "nova_sonic_api"
                    })
                }
                
        except Exception as e:
            print(f"Nova Sonic API error: {str(e)}")
        
        # Fallback to browser voice (client-side)
        return {
            "statusCode": 200,
            "headers": {"Content-Type": "application/json"},
            "body": json.dumps({
                "success": True,
                "use_browser_voice": True,
                "text": text,
                "voice_type": "browser_fallback"
            })
        }
        
    except Exception as e:
        return {
            "statusCode": 500,
            "headers": {"Content-Type": "application/json"},
            "body": json.dumps({
                "success": False,
                "error": str(e)
            })
        }

def handle_health_check():
    """Handle health check"""
    return {
        "statusCode": 200,
        "headers": {"Content-Type": "application/json"},
        "body": json.dumps({
            "status": "healthy",
            "maya_voice": "professional_with_fallback",
            "greeting": "Hello (timezone-friendly)",
            "ui": "clean_without_technical_details"
        })
    }
'''
    
    return lambda_code

def deploy_clean_ui():
    """Deploy clean UI without technical details"""
    
    print("üßπ Deploying Clean UI and Voice Fix")
    print("=" * 40)
    
    # Create lambda code
    lambda_code = create_clean_ui_lambda()
    
    # Write to file
    with open('lambda_function.py', 'w') as f:
        f.write(lambda_code)
    
    # Create deployment package
    with zipfile.ZipFile('clean_ui_fix_voice.zip', 'w') as zipf:
        zipf.write('lambda_function.py')
    
    # Deploy to AWS
    try:
        lambda_client = boto3.client('lambda', region_name='us-east-1')
        
        with open('clean_ui_fix_voice.zip', 'rb') as f:
            lambda_client.update_function_code(
                FunctionName='ielts-genai-prep-api',
                ZipFile=f.read()
            )
        
        print("‚úÖ Clean UI deployed successfully!")
        print("üéµ Testing clean interface...")
        
        # Test deployment
        time.sleep(5)
        
        # Test speaking assessment
        try:
            import urllib.request
            response = urllib.request.urlopen('https://www.ieltsaiprep.com/assessment/academic-speaking')
            if response.getcode() == 200:
                print("‚úÖ Clean speaking assessment is now live!")
                
                # Check for removed boxes
                content = response.read().decode('utf-8')
                if "Nova Sonic Features" not in content:
                    print("‚úÖ Nova Sonic Features box removed!")
                if "Nova Sonic Status" not in content:
                    print("‚úÖ Nova Sonic Status box removed!")
                if "Assessment Instructions" in content:
                    print("‚úÖ User-friendly instructions added!")
                    
            else:
                print(f"‚ö†Ô∏è Speaking assessment returned status {response.getcode()}")
        except Exception as e:
            print(f"‚ö†Ô∏è Speaking assessment test failed: {str(e)}")
        
        print("\nüéØ Clean UI Features:")
        print("‚Ä¢ ‚úÖ Removed Nova Sonic Features box (backend details hidden)")
        print("‚Ä¢ ‚úÖ Removed Nova Sonic Status box (not relevant to IELTS)")
        print("‚Ä¢ ‚úÖ Added user-friendly assessment instructions")
        print("‚Ä¢ ‚úÖ Clean interface focused on IELTS experience")
        print("‚Ä¢ ‚úÖ Working voice with proper fallback")
        print("‚Ä¢ ‚úÖ Professional appearance without technical jargon")
        
    except Exception as e:
        print(f"‚ùå Deployment failed: {str(e)}")
        return False
    
    return True

if __name__ == "__main__":
    deploy_clean_ui()